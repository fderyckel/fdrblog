[
  {
    "objectID": "posts/welcome/index.html",
    "href": "posts/welcome/index.html",
    "title": "Welcome To My Blog",
    "section": "",
    "text": "Since this post doesn’t specify an explicit image, the first image in the post will be used in the listing page of posts."
  },
  {
    "objectID": "posts/extrapolate-wtih-decision-tree/index.html",
    "href": "posts/extrapolate-wtih-decision-tree/index.html",
    "title": "Extrapolate with Decision Trees",
    "section": "",
    "text": "The idea of this document is to show how Xgboost can be especially bad at extrapolating or make prediction out of range of given data. This idea of this post come from this blog"
  },
  {
    "objectID": "posts/extrapolate-wtih-decision-tree/index.html#using-r",
    "href": "posts/extrapolate-wtih-decision-tree/index.html#using-r",
    "title": "Extrapolate with Decision Trees",
    "section": "Using R",
    "text": "Using R\n\nlibrary(tibble)\nlibrary(dplyr)\nlibrary(ggplot2)\nlibrary(parsnip)\n\nset.seed(123)\ndf <- tibble(t = seq(1:100), \n             y = t + 2 * rnorm(100, mean = 0, sd = 1))\n\n#The first 50 observation to be used for training and the last 50 for testing.\ndf_train <- df[1:50, ]\ndf_test <- df[51:100, ]\n\nmodel = decision_tree(mode = \"regression\", engine = \"rpart\", tree_depth = 2) \nmodel_fit = model %>% fit(y ~ t, data = df_train)\nmodel_fit\n\nparsnip model object\n\nn= 50 \n\nnode), split, n, deviance, yval\n      * denotes terminal node\n\n1) root 50 10523.98000 25.568810  \n  2) t< 26.5 26  1260.25700 13.306160  \n    4) t< 10.5 10    88.19884  5.649251 *\n    5) t>=10.5 16   219.34920 18.091720 *\n  3) t>=26.5 24  1118.54600 38.853340  \n    6) t< 41.5 15   255.91590 34.484340 *\n    7) t>=41.5 9    99.10379 46.135010 *\n\ny_predict <- add_row(predict(model_fit, df_train),  predict(model_fit, df_test) )\n\ndf <- df |> add_column( y_predict)\ntail(df)\n\n# A tibble: 6 × 3\n      t     y .pred\n  <int> <dbl> <dbl>\n1    95  97.7  46.1\n2    96  94.8  46.1\n3    97 101.   46.1\n4    98 101.   46.1\n5    99  98.5  46.1\n6   100  97.9  46.1\n\nggplot() + \n  geom_line(aes(x = t, y = y, color = \"a\"), data = df[1:50, ], show.legend = TRUE) + \n  geom_line(aes(x = t, y = y, color=\"a\"), lty=2, data = df[50:100, ]) + \n  geom_line(aes(x=t, y = .pred, color = \"b\"), data = df[1:50, ]) + \n  geom_line(aes(x = t, y = .pred, color = \"c\"), lty=2, data = df[50:100, ]) + \n  scale_color_manual(name = \"Legend\", \n                     values = c(\"a\" = \"blue\", \"b\" = \"red\", \"c\" = \"purple\"), \n                     labels = c(\"Data\", \"In sample testing\", \"Out of sample testing\")) + \n  theme(legend.position = \"bottom\")\n\n\n\n\nFigure 1: Performance of decision tree on a linear trend"
  },
  {
    "objectID": "posts/post-with-code/index.html",
    "href": "posts/post-with-code/index.html",
    "title": "Post With Code",
    "section": "",
    "text": "1 + 1\n\n[1] 2"
  },
  {
    "objectID": "about.html",
    "href": "about.html",
    "title": "About",
    "section": "",
    "text": "About this blog"
  },
  {
    "objectID": "index.html",
    "href": "index.html",
    "title": "Fdr Blog",
    "section": "",
    "text": "decision_tree\n\n\ncode\n\n\nanalysis\n\n\n\n\n\n\n\n\n\n\n\nSep 25, 2022\n\n\nFrancois de Ryckel\n\n\n\n\n\n\n  \n\n\n\n\n\n\n\n\n\n\nnews\n\n\ncode\n\n\nanalysis\n\n\n\n\n\n\n\n\n\n\n\nSep 25, 2022\n\n\nHarlow Malloc\n\n\n\n\n\n\n  \n\n\n\n\n\n\n\n\n\n\nnews\n\n\n\n\n\n\n\n\n\n\n\nSep 22, 2022\n\n\nTristan O’Malley\n\n\n\n\n\n\nNo matching items"
  }
]