[
  {
    "objectID": "my_env/lib/python3.10/site-packages/pyzmq-24.0.1.dist-info/AUTHORS.html",
    "href": "my_env/lib/python3.10/site-packages/pyzmq-24.0.1.dist-info/AUTHORS.html",
    "title": "Documenting my R/Python learning journey",
    "section": "",
    "text": "This project was started and continues to be led by Brian E. Granger (ellisonbg AT gmail DOT com). Min Ragan-Kelley (benjaminrk AT gmail DOT com) is the primary developer of pyzmq at this time.\nThe following people have contributed to the project:\n\nAlexander Else (alexander DOT else AT team DOT telstra DOT com)\nAlexander Pyhalov (apyhalov AT gmail DOT com)\nAlexandr Emelin (frvzmb AT gmail DOT com)\nAmr Ali (amr AT ledgerx DOT com)\nAndre Caron (andre DOT l DOT caron AT gmail DOT com)\nAndrea Crotti (andrea DOT crotti DOT 0 AT gmail DOT com)\nAndrew Gwozdziewycz (git AT apgwoz DOT com)\nBaptiste Lepilleur (baptiste DOT lepilleur AT gmail DOT com)\nBrandyn A. White (bwhite AT dappervision DOT com)\nBrian E. Granger (ellisonbg AT gmail DOT com)\nBrian Hoffman (hoffman_brian AT bah DOT com)\nCarlos A. Rocha (carlos DOT rocha AT gmail DOT com)\nChris Laws (clawsicus AT gmail DOT com)\nChristian Wyglendowski (christian AT bu DOT mp)\nChristoph Gohlke (cgohlke AT uci DOT edu)\nCurtis (curtis AT tinbrain DOT net)\nCyril Holweck (cyril DOT holweck AT free DOT fr)\nDan Colish (dcolish AT gmail DOT com)\nDaniel Lundin (dln AT eintr DOT org)\nDaniel Truemper (truemped AT googlemail DOT com)\nDouglas Creager (douglas DOT creager AT redjack DOT com)\nEduardo Stalinho (eduardooc DOT 86 AT gmail DOT com)\nEren Güven (erenguven0 AT gmail DOT com)\nErick Tryzelaar (erick DOT tryzelaar AT gmail DOT com)\nErik Tollerud (erik DOT tollerud AT gmail DOT com)\nFELD Boris (lothiraldan AT gmail DOT com)\nFantix King (fantix DOT king AT gmail DOT com)\nFelipe Cruz (felipecruz AT loogica DOT net)\nFernando Perez (Fernando DOT Perez AT berkeley DOT edu)\nFrank Wiles (frank AT revsys DOT com)\nFélix-Antoine Fortin (felix DOT antoine DOT fortin AT gmail DOT com)\nGavrie Philipson (gavriep AT il DOT ibm DOT com)\nGodefroid Chapelle (gotcha AT bubblenet DOT be)\nGreg Banks (gbanks AT mybasis DOT com)\nGreg Ward (greg AT gerg DOT ca)\nGuido Goldstein (github AT a-nugget DOT de)\nIan Lee (IanLee1521 AT gmail DOT com)\nIonuț Arțăriși (ionut AT artarisi DOT eu)\nIvo Danihelka (ivo AT danihelka DOT net)\nIyed (iyed DOT bennour AT gmail DOT com)\nJim Garrison (jim AT garrison DOT cc)\nJohn Gallagher (johnkgallagher AT gmail DOT com)\nJulian Taylor (jtaylor DOT debian AT googlemail DOT com)\nJustin Bronder (jsbronder AT gmail DOT com)\nJustin Riley (justin DOT t DOT riley AT gmail DOT com)\nMarc Abramowitz (marc AT marc-abramowitz DOT com)\nMatthew Aburn (mattja6 AT gmail DOT com)\nMichel Pelletier (pelletier DOT michel AT gmail DOT com)\nMichel Zou (xantares09 AT hotmail DOT com)\nMin Ragan-Kelley (benjaminrk AT gmail DOT com)\nNell Hardcastle (nell AT dev-nell DOT com)\nNicholas Pilkington (nicholas DOT pilkington AT gmail DOT com)\nNicholas Piël (nicholas AT nichol DOT as)\nNick Pellegrino (npellegrino AT mozilla DOT com)\nNicolas Delaby (nicolas DOT delaby AT ezeep DOT com)\nOndrej Certik (ondrej AT certik DOT cz)\nPaul Colomiets (paul AT colomiets DOT name)\nPawel Jasinski (pawel DOT jasinski AT gmail DOT com)\nPhus Lu (phus DOT lu AT gmail DOT com)\nRobert Buchholz (rbu AT goodpoint DOT de)\nRobert Jordens (jordens AT gmail DOT com)\nRyan Cox (ryan DOT a DOT cox AT gmail DOT com)\nRyan Kelly (ryan AT rfk DOT id DOT au)\nScott Maxwell (scott AT codecobblers DOT com)\nScott Sadler (github AT mashi DOT org)\nSimon Knight (simon DOT knight AT gmail DOT com)\nStefan Friesel (sf AT cloudcontrol DOT de)\nStefan van der Walt (stefan AT sun DOT ac DOT za)\nStephen Diehl (stephen DOT m DOT diehl AT gmail DOT com)\nSylvain Corlay (scorlay AT bloomberg DOT net)\nThomas Kluyver (takowl AT gmail DOT com)\nThomas Spura (tomspur AT fedoraproject DOT org)\nTigger Bear (Tigger AT Tiggers-Mac-mini DOT local)\nTorsten Landschoff (torsten DOT landschoff AT dynamore DOT de)\nVadim Markovtsev (v DOT markovtsev AT samsung DOT com)\nYannick Hold (yannickhold AT gmail DOT com)\nZbigniew Jędrzejewski-Szmek (zbyszek AT in DOT waw DOT pl)\nhugo shi (hugoshi AT bleb2 DOT (none))\njdgleeson (jdgleeson AT mac DOT com)\nkyledj (kyle AT bucebuce DOT com)\nspez (steve AT hipmunk DOT com)\nstu (stuart DOT axon AT jpcreative DOT co DOT uk)\nxantares (xantares AT fujitsu-l64 DOT (none))\n\nas reported by:\ngit log --all --format='- %aN (%aE)' | sort -u | sed 's/@/ AT /1' | sed -e 's/\\.\\([^ ]\\)/ DOT \\1/g'\nwith some adjustments.\n\n\n\nBrandon Craig-Rhodes (brandon AT rhodesmill DOT org)\nEugene Chernyshov (chernyshov DOT eugene AT gmail DOT com)\nCraig Austin (craig DOT austin AT gmail DOT com)\n\n\n\n\n\nTravis Cline (travis DOT cline AT gmail DOT com)\nRyan Kelly (ryan AT rfk DOT id DOT au)\nZachary Voase (z AT zacharyvoase DOT com)"
  },
  {
    "objectID": "my_env/lib/python3.10/site-packages/matplotlib/backends/web_backend/nbagg_uat.html",
    "href": "my_env/lib/python3.10/site-packages/matplotlib/backends/web_backend/nbagg_uat.html",
    "title": "Documenting my R/Python learning journey",
    "section": "",
    "text": "from imp import reload"
  },
  {
    "objectID": "my_env/lib/python3.10/site-packages/matplotlib/backends/web_backend/nbagg_uat.html#uat-for-nbagg-backend.",
    "href": "my_env/lib/python3.10/site-packages/matplotlib/backends/web_backend/nbagg_uat.html#uat-for-nbagg-backend.",
    "title": "Documenting my R/Python learning journey",
    "section": "UAT for NbAgg backend.",
    "text": "UAT for NbAgg backend.\nThe first line simply reloads matplotlib, uses the nbagg backend and then reloads the backend, just to ensure we have the latest modification to the backend code. Note: The underlying JavaScript will not be updated by this process, so a refresh of the browser after clearing the output and saving is necessary to clear everything fully.\n\nimport matplotlib\nreload(matplotlib)\n\nmatplotlib.use('nbagg')\n\nimport matplotlib.backends.backend_nbagg\nreload(matplotlib.backends.backend_nbagg)\n\n\nUAT 1 - Simple figure creation using pyplot\nShould produce a figure window which is interactive with the pan and zoom buttons. (Do not press the close button, but any others may be used).\n\nimport matplotlib.backends.backend_webagg_core\nreload(matplotlib.backends.backend_webagg_core)\n\nimport matplotlib.pyplot as plt\nplt.interactive(False)\n\nfig1 = plt.figure()\nplt.plot(range(10))\n\nplt.show()\n\n\n\nUAT 2 - Creation of another figure, without the need to do plt.figure.\nAs above, a new figure should be created.\n\nplt.plot([3, 2, 1])\nplt.show()\n\n\n\nUAT 3 - Connection info\nThe printout should show that there are two figures which have active CommSockets, and no figures pending show.\n\nprint(matplotlib.backends.backend_nbagg.connection_info())\n\n\n\nUAT 4 - Closing figures\nClosing a specific figure instance should turn the figure into a plain image - the UI should have been removed. In this case, scroll back to the first figure and assert this is the case.\n\nplt.close(fig1)\nplt.close('all')\n\n\n\nUAT 5 - No show without plt.show in non-interactive mode\nSimply doing a plt.plot should not show a new figure, nor indeed update an existing one (easily verified in UAT 6). The output should simply be a list of Line2D instances.\n\nplt.plot(range(10))\n\n\n\nUAT 6 - Connection information\nWe just created a new figure, but didn’t show it. Connection info should no longer have “Figure 1” (as we closed it in UAT 4) and should have figure 2 and 3, with Figure 3 without any connections. There should be 1 figure pending.\n\nprint(matplotlib.backends.backend_nbagg.connection_info())\n\n\n\nUAT 7 - Show of previously created figure\nWe should be able to show a figure we’ve previously created. The following should produce two figure windows.\n\nplt.show()\nplt.figure()\nplt.plot(range(5))\nplt.show()\n\n\n\nUAT 8 - Interactive mode\nIn interactive mode, creating a line should result in a figure being shown.\n\nplt.interactive(True)\nplt.figure()\nplt.plot([3, 2, 1])\n\nSubsequent lines should be added to the existing figure, rather than creating a new one.\n\nplt.plot(range(3))\n\nCalling connection_info in interactive mode should not show any pending figures.\n\nprint(matplotlib.backends.backend_nbagg.connection_info())\n\nDisable interactive mode again.\n\nplt.interactive(False)\n\n\n\nUAT 9 - Multiple shows\nUnlike most of the other matplotlib backends, we may want to see a figure multiple times (with or without synchronisation between the views, though the former is not yet implemented). Assert that plt.gcf().canvas.manager.reshow() results in another figure window which is synchronised upon pan & zoom.\n\nplt.gcf().canvas.manager.reshow()\n\n\n\nUAT 10 - Saving notebook\nSaving the notebook (with CTRL+S or File->Save) should result in the saved notebook having static versions of the figures embedded within. The image should be the last update from user interaction and interactive plotting. (check by converting with ipython nbconvert <notebook>)\n\n\nUAT 11 - Creation of a new figure on second show\nCreate a figure, show it, then create a new axes and show it. The result should be a new figure.\nBUG: Sometimes this doesn’t work - not sure why (@pelson).\n\nfig = plt.figure()\nplt.axes()\nplt.show()\n\nplt.plot([1, 2, 3])\nplt.show()\n\n\n\nUAT 12 - OO interface\nShould produce a new figure and plot it.\n\nfrom matplotlib.backends.backend_nbagg import new_figure_manager,show\n\nmanager = new_figure_manager(1000)\nfig = manager.canvas.figure\nax = fig.add_subplot(1,1,1)\nax.plot([1,2,3])\nfig.show()"
  },
  {
    "objectID": "my_env/lib/python3.10/site-packages/matplotlib/backends/web_backend/nbagg_uat.html#uat-13---animation",
    "href": "my_env/lib/python3.10/site-packages/matplotlib/backends/web_backend/nbagg_uat.html#uat-13---animation",
    "title": "Documenting my R/Python learning journey",
    "section": "UAT 13 - Animation",
    "text": "UAT 13 - Animation\nThe following should generate an animated line:\n\nimport matplotlib.animation as animation\nimport numpy as np\n\nfig, ax = plt.subplots()\n\nx = np.arange(0, 2*np.pi, 0.01)        # x-array\nline, = ax.plot(x, np.sin(x))\n\ndef animate(i):\n    line.set_ydata(np.sin(x+i/10.0))  # update the data\n    return line,\n\n#Init only required for blitting to give a clean slate.\ndef init():\n    line.set_ydata(np.ma.array(x, mask=True))\n    return line,\n\nani = animation.FuncAnimation(fig, animate, np.arange(1, 200), init_func=init,\n                              interval=100., blit=True)\nplt.show()\n\n\nUAT 14 - Keyboard shortcuts in IPython after close of figure\nAfter closing the previous figure (with the close button above the figure) the IPython keyboard shortcuts should still function.\n\n\nUAT 15 - Figure face colours\nThe nbagg honours all colours apart from that of the figure.patch. The two plots below should produce a figure with a red background. There should be no yellow figure.\n\nimport matplotlib\nmatplotlib.rcParams.update({'figure.facecolor': 'red',\n                            'savefig.facecolor': 'yellow'})\nplt.figure()\nplt.plot([3, 2, 1])\n\nplt.show()\n\n\n\nUAT 16 - Events\nPressing any keyboard key or mouse button (or scrolling) should cycle the line while the figure has focus. The figure should have focus by default when it is created and re-gain it by clicking on the canvas. Clicking anywhere outside of the figure should release focus, but moving the mouse out of the figure should not release focus.\n\nimport itertools\nfig, ax = plt.subplots()\nx = np.linspace(0,10,10000)\ny = np.sin(x)\nln, = ax.plot(x,y)\nevt = []\ncolors = iter(itertools.cycle(['r', 'g', 'b', 'k', 'c']))\ndef on_event(event):\n    if event.name.startswith('key'):\n        fig.suptitle('%s: %s' % (event.name, event.key))\n    elif event.name == 'scroll_event':\n        fig.suptitle('%s: %s' % (event.name, event.step))\n    else:\n        fig.suptitle('%s: %s' % (event.name, event.button))\n    evt.append(event)\n    ln.set_color(next(colors))\n    fig.canvas.draw()\n    fig.canvas.draw_idle()\n\nfig.canvas.mpl_connect('button_press_event', on_event)\nfig.canvas.mpl_connect('button_release_event', on_event)\nfig.canvas.mpl_connect('scroll_event', on_event)\nfig.canvas.mpl_connect('key_press_event', on_event)\nfig.canvas.mpl_connect('key_release_event', on_event)\n\nplt.show()\n\n\n\nUAT 17 - Timers\nSingle-shot timers follow a completely different code path in the nbagg backend than regular timers (such as those used in the animation example above.) The next set of tests ensures that both “regular” and “single-shot” timers work properly.\nThe following should show a simple clock that updates twice a second:\n\nimport time\n\nfig, ax = plt.subplots()\ntext = ax.text(0.5, 0.5, '', ha='center')\n\ndef update(text):\n    text.set(text=time.ctime())\n    text.axes.figure.canvas.draw()\n    \ntimer = fig.canvas.new_timer(500, [(update, [text], {})])\ntimer.start()\nplt.show()\n\nHowever, the following should only update once and then stop:\n\nfig, ax = plt.subplots()\ntext = ax.text(0.5, 0.5, '', ha='center') \ntimer = fig.canvas.new_timer(500, [(update, [text], {})])\n\ntimer.single_shot = True\ntimer.start()\n\nplt.show()\n\nAnd the next two examples should never show any visible text at all:\n\nfig, ax = plt.subplots()\ntext = ax.text(0.5, 0.5, '', ha='center')\ntimer = fig.canvas.new_timer(500, [(update, [text], {})])\n\ntimer.start()\ntimer.stop()\n\nplt.show()\n\n\nfig, ax = plt.subplots()\ntext = ax.text(0.5, 0.5, '', ha='center')\ntimer = fig.canvas.new_timer(500, [(update, [text], {})])\n\ntimer.single_shot = True\ntimer.start()\ntimer.stop()\n\nplt.show()\n\n\n\nUAT 18 - stopping figure when removed from DOM\nWhen the div that contains from the figure is removed from the DOM the figure should shut down it’s comm, and if the python-side figure has no more active comms, it should destroy the figure. Repeatedly running the cell below should always have the same figure number\n\nfig, ax = plt.subplots()\nax.plot(range(5))\nplt.show()\n\nRunning the cell below will re-show the figure. After this, re-running the cell above should result in a new figure number.\n\nfig.canvas.manager.reshow()\n\n\n\nUAT 19 - Blitting\nClicking on the figure should plot a green horizontal line moving up the axes.\n\nimport itertools\n\ncnt = itertools.count()\nbg = None\n\ndef onclick_handle(event):\n    \"\"\"Should draw elevating green line on each mouse click\"\"\"\n    global bg\n    if bg is None:\n        bg = ax.figure.canvas.copy_from_bbox(ax.bbox) \n    ax.figure.canvas.restore_region(bg)\n\n    cur_y = (next(cnt) % 10) * 0.1\n    ln.set_ydata([cur_y, cur_y])\n    ax.draw_artist(ln)\n    ax.figure.canvas.blit(ax.bbox)\n\nfig, ax = plt.subplots()\nax.plot([0, 1], [0, 1], 'r')\nln, = ax.plot([0, 1], [0, 0], 'g', animated=True)\nplt.show()\nax.figure.canvas.draw()\n\nax.figure.canvas.mpl_connect('button_press_event', onclick_handle)"
  },
  {
    "objectID": "my_env/lib/python3.10/site-packages/traitlets-5.4.0.dist-info/licenses/COPYING.html",
    "href": "my_env/lib/python3.10/site-packages/traitlets-5.4.0.dist-info/licenses/COPYING.html",
    "title": "Documenting my R/Python learning journey",
    "section": "",
    "text": "Traitlets is adapted from enthought.traits, Copyright (c) Enthought, Inc., under the terms of the Modified BSD License.\nThis project is licensed under the terms of the Modified BSD License (also known as New or Revised or 3-Clause BSD), as follows:\n\nCopyright (c) 2001-, IPython Development Team\n\nAll rights reserved.\nRedistribution and use in source and binary forms, with or without modification, are permitted provided that the following conditions are met:\nRedistributions of source code must retain the above copyright notice, this list of conditions and the following disclaimer.\nRedistributions in binary form must reproduce the above copyright notice, this list of conditions and the following disclaimer in the documentation and/or other materials provided with the distribution.\nNeither the name of the IPython Development Team nor the names of its contributors may be used to endorse or promote products derived from this software without specific prior written permission.\nTHIS SOFTWARE IS PROVIDED BY THE COPYRIGHT HOLDERS AND CONTRIBUTORS “AS IS” AND ANY EXPRESS OR IMPLIED WARRANTIES, INCLUDING, BUT NOT LIMITED TO, THE IMPLIED WARRANTIES OF MERCHANTABILITY AND FITNESS FOR A PARTICULAR PURPOSE ARE DISCLAIMED. IN NO EVENT SHALL THE COPYRIGHT OWNER OR CONTRIBUTORS BE LIABLE FOR ANY DIRECT, INDIRECT, INCIDENTAL, SPECIAL, EXEMPLARY, OR CONSEQUENTIAL DAMAGES (INCLUDING, BUT NOT LIMITED TO, PROCUREMENT OF SUBSTITUTE GOODS OR SERVICES; LOSS OF USE, DATA, OR PROFITS; OR BUSINESS INTERRUPTION) HOWEVER CAUSED AND ON ANY THEORY OF LIABILITY, WHETHER IN CONTRACT, STRICT LIABILITY, OR TORT (INCLUDING NEGLIGENCE OR OTHERWISE) ARISING IN ANY WAY OUT OF THE USE OF THIS SOFTWARE, EVEN IF ADVISED OF THE POSSIBILITY OF SUCH DAMAGE.\n\n\nThe IPython Development Team is the set of all contributors to the IPython project. This includes all of the IPython subprojects.\nThe core team that coordinates development on GitHub can be found here: https://github.com/jupyter/.\n\n\n\nIPython uses a shared copyright model. Each contributor maintains copyright over their contributions to IPython. But, it is important to note that these contributions are typically only changes to the repositories. Thus, the IPython source code, in its entirety is not the copyright of any single person or institution. Instead, it is the collective copyright of the entire IPython Development Team. If individual contributors want to maintain a record of what changes/contributions they have specific copyright on, they should indicate their copyright in the commit message of the change, when they commit the change to one of the IPython repositories.\nWith this in mind, the following banner should be used in any source code file to indicate the copyright and license terms:\n# Copyright (c) IPython Development Team.\n# Distributed under the terms of the Modified BSD License."
  },
  {
    "objectID": "my_env/lib/python3.10/site-packages/ipykernel-6.16.0.dist-info/licenses/COPYING.html",
    "href": "my_env/lib/python3.10/site-packages/ipykernel-6.16.0.dist-info/licenses/COPYING.html",
    "title": "Documenting my R/Python learning journey",
    "section": "",
    "text": "This project is licensed under the terms of the Modified BSD License (also known as New or Revised or 3-Clause BSD), as follows:\n\nCopyright (c) 2015, IPython Development Team\n\nAll rights reserved.\nRedistribution and use in source and binary forms, with or without modification, are permitted provided that the following conditions are met:\nRedistributions of source code must retain the above copyright notice, this list of conditions and the following disclaimer.\nRedistributions in binary form must reproduce the above copyright notice, this list of conditions and the following disclaimer in the documentation and/or other materials provided with the distribution.\nNeither the name of the IPython Development Team nor the names of its contributors may be used to endorse or promote products derived from this software without specific prior written permission.\nTHIS SOFTWARE IS PROVIDED BY THE COPYRIGHT HOLDERS AND CONTRIBUTORS “AS IS” AND ANY EXPRESS OR IMPLIED WARRANTIES, INCLUDING, BUT NOT LIMITED TO, THE IMPLIED WARRANTIES OF MERCHANTABILITY AND FITNESS FOR A PARTICULAR PURPOSE ARE DISCLAIMED. IN NO EVENT SHALL THE COPYRIGHT OWNER OR CONTRIBUTORS BE LIABLE FOR ANY DIRECT, INDIRECT, INCIDENTAL, SPECIAL, EXEMPLARY, OR CONSEQUENTIAL DAMAGES (INCLUDING, BUT NOT LIMITED TO, PROCUREMENT OF SUBSTITUTE GOODS OR SERVICES; LOSS OF USE, DATA, OR PROFITS; OR BUSINESS INTERRUPTION) HOWEVER CAUSED AND ON ANY THEORY OF LIABILITY, WHETHER IN CONTRACT, STRICT LIABILITY, OR TORT (INCLUDING NEGLIGENCE OR OTHERWISE) ARISING IN ANY WAY OUT OF THE USE OF THIS SOFTWARE, EVEN IF ADVISED OF THE POSSIBILITY OF SUCH DAMAGE.\n\n\nThe IPython Development Team is the set of all contributors to the IPython project. This includes all of the IPython subprojects.\nThe core team that coordinates development on GitHub can be found here: https://github.com/ipython/.\n\n\n\nIPython uses a shared copyright model. Each contributor maintains copyright over their contributions to IPython. But, it is important to note that these contributions are typically only changes to the repositories. Thus, the IPython source code, in its entirety is not the copyright of any single person or institution. Instead, it is the collective copyright of the entire IPython Development Team. If individual contributors want to maintain a record of what changes/contributions they have specific copyright on, they should indicate their copyright in the commit message of the change, when they commit the change to one of the IPython repositories.\nWith this in mind, the following banner should be used in any source code file to indicate the copyright and license terms:\n# Copyright (c) IPython Development Team.\n# Distributed under the terms of the Modified BSD License."
  },
  {
    "objectID": "my_env/lib/python3.10/site-packages/QtPy-2.2.0.dist-info/AUTHORS.html",
    "href": "my_env/lib/python3.10/site-packages/QtPy-2.2.0.dist-info/AUTHORS.html",
    "title": "Documenting my R/Python learning journey",
    "section": "",
    "text": "pyqode.qt: Colin Duquesnoy (@ColinDuquesnoy)\nspyderlib.qt: Pierre Raybaut (@PierreRaybaut)\nqt-helpers: Thomas Robitaille (@astrofrog)\n\n\n\n\n\nDaniel Althviz (@dalthviz)\nCarlos Cordoba (@ccordoba12)\nC.A.M. Gerlach (@CAM-Gerlach)\nSpyder Development Team (Spyder-IDE)\n\n\n\n\n\nThe QtPy Contributors"
  },
  {
    "objectID": "my_env/lib/python3.10/site-packages/idna-3.4.dist-info/LICENSE.html",
    "href": "my_env/lib/python3.10/site-packages/idna-3.4.dist-info/LICENSE.html",
    "title": "Documenting my R/Python learning journey",
    "section": "",
    "text": "Copyright (c) 2013-2021, Kim Davies All rights reserved.\nRedistribution and use in source and binary forms, with or without modification, are permitted provided that the following conditions are met:\n\nRedistributions of source code must retain the above copyright notice, this list of conditions and the following disclaimer.\nRedistributions in binary form must reproduce the above copyright notice, this list of conditions and the following disclaimer in the documentation and/or other materials provided with the distribution.\nNeither the name of the copyright holder nor the names of its contributors may be used to endorse or promote products derived from this software without specific prior written permission.\n\nTHIS SOFTWARE IS PROVIDED BY THE COPYRIGHT HOLDERS AND CONTRIBUTORS “AS IS” AND ANY EXPRESS OR IMPLIED WARRANTIES, INCLUDING, BUT NOT LIMITED TO, THE IMPLIED WARRANTIES OF MERCHANTABILITY AND FITNESS FOR A PARTICULAR PURPOSE ARE DISCLAIMED. IN NO EVENT SHALL THE COPYRIGHT HOLDER OR CONTRIBUTORS BE LIABLE FOR ANY DIRECT, INDIRECT, INCIDENTAL, SPECIAL, EXEMPLARY, OR CONSEQUENTIAL DAMAGES (INCLUDING, BUT NOT LIMITED TO, PROCUREMENT OF SUBSTITUTE GOODS OR SERVICES; LOSS OF USE, DATA, OR PROFITS; OR BUSINESS INTERRUPTION) HOWEVER CAUSED AND ON ANY THEORY OF LIABILITY, WHETHER IN CONTRACT, STRICT LIABILITY, OR TORT (INCLUDING NEGLIGENCE OR OTHERWISE) ARISING IN ANY WAY OUT OF THE USE OF THIS SOFTWARE, EVEN IF ADVISED OF THE POSSIBILITY OF SUCH DAMAGE."
  },
  {
    "objectID": "my_env/lib/python3.10/site-packages/jupyter_client-7.3.5.dist-info/licenses/COPYING.html",
    "href": "my_env/lib/python3.10/site-packages/jupyter_client-7.3.5.dist-info/licenses/COPYING.html",
    "title": "Documenting my R/Python learning journey",
    "section": "",
    "text": "This project is licensed under the terms of the Modified BSD License (also known as New or Revised or 3-Clause BSD), as follows:\n\nCopyright (c) 2001-2015, IPython Development Team\nCopyright (c) 2015-, Jupyter Development Team\n\nAll rights reserved.\nRedistribution and use in source and binary forms, with or without modification, are permitted provided that the following conditions are met:\nRedistributions of source code must retain the above copyright notice, this list of conditions and the following disclaimer.\nRedistributions in binary form must reproduce the above copyright notice, this list of conditions and the following disclaimer in the documentation and/or other materials provided with the distribution.\nNeither the name of the Jupyter Development Team nor the names of its contributors may be used to endorse or promote products derived from this software without specific prior written permission.\nTHIS SOFTWARE IS PROVIDED BY THE COPYRIGHT HOLDERS AND CONTRIBUTORS “AS IS” AND ANY EXPRESS OR IMPLIED WARRANTIES, INCLUDING, BUT NOT LIMITED TO, THE IMPLIED WARRANTIES OF MERCHANTABILITY AND FITNESS FOR A PARTICULAR PURPOSE ARE DISCLAIMED. IN NO EVENT SHALL THE COPYRIGHT OWNER OR CONTRIBUTORS BE LIABLE FOR ANY DIRECT, INDIRECT, INCIDENTAL, SPECIAL, EXEMPLARY, OR CONSEQUENTIAL DAMAGES (INCLUDING, BUT NOT LIMITED TO, PROCUREMENT OF SUBSTITUTE GOODS OR SERVICES; LOSS OF USE, DATA, OR PROFITS; OR BUSINESS INTERRUPTION) HOWEVER CAUSED AND ON ANY THEORY OF LIABILITY, WHETHER IN CONTRACT, STRICT LIABILITY, OR TORT (INCLUDING NEGLIGENCE OR OTHERWISE) ARISING IN ANY WAY OUT OF THE USE OF THIS SOFTWARE, EVEN IF ADVISED OF THE POSSIBILITY OF SUCH DAMAGE.\n\n\nThe Jupyter Development Team is the set of all contributors to the Jupyter project. This includes all of the Jupyter subprojects.\nThe core team that coordinates development on GitHub can be found here: https://github.com/jupyter/.\n\n\n\nJupyter uses a shared copyright model. Each contributor maintains copyright over their contributions to Jupyter. But, it is important to note that these contributions are typically only changes to the repositories. Thus, the Jupyter source code, in its entirety is not the copyright of any single person or institution. Instead, it is the collective copyright of the entire Jupyter Development Team. If individual contributors want to maintain a record of what changes/contributions they have specific copyright on, they should indicate their copyright in the commit message of the change, when they commit the change to one of the Jupyter repositories.\nWith this in mind, the following banner should be used in any source code file to indicate the copyright and license terms:\n# Copyright (c) Jupyter Development Team.\n# Distributed under the terms of the Modified BSD License."
  },
  {
    "objectID": "my_env/lib/python3.10/site-packages/nbclient/tests/files/Unicode.html",
    "href": "my_env/lib/python3.10/site-packages/nbclient/tests/files/Unicode.html",
    "title": "Documenting my R/Python learning journey",
    "section": "",
    "text": "print('☃')\n\n☃"
  },
  {
    "objectID": "my_env/lib/python3.10/site-packages/nbclient/tests/files/update-display-id.html",
    "href": "my_env/lib/python3.10/site-packages/nbclient/tests/files/update-display-id.html",
    "title": "Documenting my R/Python learning journey",
    "section": "",
    "text": "display('above')\ndisplay_with_id(1, 'here')\ndisplay('below')\n\n'above'\n\n\n8\n\n\n'below'\n\n\n\ndisplay_with_id(2, 'here')\ndisplay_with_id(3, 'there')\ndisplay_with_id(4, 'here')\n\n8\n\n\n6\n\n\n8\n\n\n\ndisplay_with_id(5, 'there')\ndisplay_with_id(6, 'there', update=True)\n\n6\n\n\n\ndisplay_with_id(7, 'here')\ndisplay_with_id(8, 'here', update=True)\ndisplay_with_id(9, 'result', execute_result=True)\n\n8\n\n\n10\n\n\n\ndisplay_with_id(10, 'result', update=True)"
  },
  {
    "objectID": "my_env/lib/python3.10/site-packages/nbclient/tests/files/JupyterWidgets.html",
    "href": "my_env/lib/python3.10/site-packages/nbclient/tests/files/JupyterWidgets.html",
    "title": "Documenting my R/Python learning journey",
    "section": "",
    "text": "# it should also handle custom msg'es\nlabel.send({'msg': 'Hello'})"
  },
  {
    "objectID": "my_env/lib/python3.10/site-packages/nbclient/tests/files/Skip Exceptions.html",
    "href": "my_env/lib/python3.10/site-packages/nbclient/tests/files/Skip Exceptions.html",
    "title": "Documenting my R/Python learning journey",
    "section": "",
    "text": "print('ok')\n\nok"
  },
  {
    "objectID": "my_env/lib/python3.10/site-packages/nbclient/tests/files/Sleep1s.html",
    "href": "my_env/lib/python3.10/site-packages/nbclient/tests/files/Sleep1s.html",
    "title": "Documenting my R/Python learning journey",
    "section": "",
    "text": "t0 = datetime.datetime.utcnow()\ntime.sleep(1)\nt1 = datetime.datetime.utcnow()\n\n\ntime_format = '%Y-%m-%dT%H:%M:%S.%fZ'\nprint(t0.strftime(time_format), end='')\n\n\nprint(t1.strftime(time_format), end='')"
  },
  {
    "objectID": "my_env/lib/python3.10/site-packages/nbclient/tests/files/Parallel Execute B.html",
    "href": "my_env/lib/python3.10/site-packages/nbclient/tests/files/Parallel Execute B.html",
    "title": "Documenting my R/Python learning journey",
    "section": "",
    "text": "This notebook uses a file system based “lock” to assert that two instances of the notebook kernel will run in parallel. Each instance writes to a file in a temporary directory, and then tries to read the other file from the temporary directory, so that running them in sequence will fail, but running them in parallel will succeed.\nTwo notebooks are launched, each which sets the this_notebook variable. One notebook is set to this_notebook = 'A' and the other this_notebook = 'B'.\n\nimport os\nimport os.path\nimport tempfile\nimport time\n\n\n# the variable this_notebook is injectected in a cell above by the test framework.\nthis_notebook = 'B'\nother_notebook = 'A'\ndirectory = os.environ['NBEXECUTE_TEST_PARALLEL_TMPDIR']\nwith open(os.path.join(directory, 'test_file_{}.txt'.format(this_notebook)), 'w') as f:\n    f.write('Hello from {}'.format(this_notebook))\n\n\nstart = time.time()\ntimeout = 5\nend = start + timeout\ntarget_file = os.path.join(directory, 'test_file_{}.txt'.format(other_notebook))\nwhile time.time() < end:\n    time.sleep(0.1)\n    if os.path.exists(target_file):\n        with open(target_file, 'r') as f:\n            text = f.read()\n        if text == 'Hello from {}'.format(other_notebook):\n            break\nelse:\n    assert False, \"Timed out – didn't get a message from {}\".format(other_notebook)"
  },
  {
    "objectID": "my_env/lib/python3.10/site-packages/nbclient/tests/files/HelloWorld.html",
    "href": "my_env/lib/python3.10/site-packages/nbclient/tests/files/HelloWorld.html",
    "title": "Documenting my R/Python learning journey",
    "section": "",
    "text": "print(\"Hello World\")\n\nHello World"
  },
  {
    "objectID": "my_env/lib/python3.10/site-packages/nbclient/tests/files/Check History in Memory.html",
    "href": "my_env/lib/python3.10/site-packages/nbclient/tests/files/Check History in Memory.html",
    "title": "Documenting my R/Python learning journey",
    "section": "",
    "text": "ip = get_ipython()\nassert ip.history_manager.hist_file == ':memory:'"
  },
  {
    "objectID": "my_env/lib/python3.10/site-packages/nbclient/tests/files/Other Comms.html",
    "href": "my_env/lib/python3.10/site-packages/nbclient/tests/files/Other Comms.html",
    "title": "Documenting my R/Python learning journey",
    "section": "",
    "text": "comm = Comm('this-comm-tests-a-missing-handler', data={'id': 'foo'})\n\n\ncomm.send(data={'id': 'bar'})"
  },
  {
    "objectID": "my_env/lib/python3.10/site-packages/nbclient/tests/files/Disable Stdin.html",
    "href": "my_env/lib/python3.10/site-packages/nbclient/tests/files/Disable Stdin.html",
    "title": "Documenting my R/Python learning journey",
    "section": "",
    "text": "try:\n    input = raw_input\nexcept:\n    pass\n\nname = input(\"name: \")"
  },
  {
    "objectID": "my_env/lib/python3.10/site-packages/nbclient/tests/files/SVG.html",
    "href": "my_env/lib/python3.10/site-packages/nbclient/tests/files/SVG.html",
    "title": "Documenting my R/Python learning journey",
    "section": "",
    "text": "SVG(data='''\n<svg height=\"100\" width=\"100\">\n    <circle cx=\"50\" cy=\"50\" r=\"40\" stroke=\"black\" stroke-width=\"2\" fill=\"red\" />\n</svg>''')"
  },
  {
    "objectID": "my_env/lib/python3.10/site-packages/nbclient/tests/files/Parallel Execute A.html",
    "href": "my_env/lib/python3.10/site-packages/nbclient/tests/files/Parallel Execute A.html",
    "title": "Documenting my R/Python learning journey",
    "section": "",
    "text": "This notebook uses a file system based “lock” to assert that two instances of the notebook kernel will run in parallel. Each instance writes to a file in a temporary directory, and then tries to read the other file from the temporary directory, so that running them in sequence will fail, but running them in parallel will succeed.\nTwo notebooks are launched, each which sets the this_notebook variable. One notebook is set to this_notebook = 'A' and the other this_notebook = 'B'.\n\nimport os\nimport os.path\nimport tempfile\nimport time\n\n\n# the variable this_notebook is injectected in a cell above by the test framework.\nthis_notebook = 'A'\nother_notebook = 'B'\ndirectory = os.environ['NBEXECUTE_TEST_PARALLEL_TMPDIR']\nwith open(os.path.join(directory, 'test_file_{}.txt'.format(this_notebook)), 'w') as f:\n    f.write('Hello from {}'.format(this_notebook))\n\n\nstart = time.time()\ntimeout = 5\nend = start + timeout\ntarget_file = os.path.join(directory, 'test_file_{}.txt'.format(other_notebook))\nwhile time.time() < end:\n    time.sleep(0.1)\n    if os.path.exists(target_file):\n        with open(target_file, 'r') as f:\n            text = f.read()\n        if text == 'Hello from {}'.format(other_notebook):\n            break\nelse:\n    assert False, \"Timed out – didn't get a message from {}\".format(other_notebook)"
  },
  {
    "objectID": "my_env/lib/python3.10/site-packages/nbclient/tests/files/UnicodePy3.html",
    "href": "my_env/lib/python3.10/site-packages/nbclient/tests/files/UnicodePy3.html",
    "title": "Documenting my R/Python learning journey",
    "section": "",
    "text": "print('☃')\n\n☃"
  },
  {
    "objectID": "my_env/lib/python3.10/site-packages/nbclient/tests/files/Autokill.html",
    "href": "my_env/lib/python3.10/site-packages/nbclient/tests/files/Autokill.html",
    "title": "Documenting my R/Python learning journey",
    "section": "",
    "text": "import os\nimport signal\npid = os.getpid()\nos.kill(pid, signal.SIGTERM)"
  },
  {
    "objectID": "my_env/lib/python3.10/site-packages/nbclient/tests/files/Output.html",
    "href": "my_env/lib/python3.10/site-packages/nbclient/tests/files/Output.html",
    "title": "Documenting my R/Python learning journey",
    "section": "",
    "text": "print(\"hi\")\nwith output1:\n    print(\"in output\")\n\nhi\n\n\n\nwith output1:\n    raise ValueError(\"trigger msg_type=error\")\n\n\nimport ipywidgets as widgets\noutput2 = widgets.Output()\noutput2\n\n\n\n\n\nprint(\"hi2\")\nwith output2:\n    print(\"in output2\")\n    clear_output(wait=True)\n\nhi2\n\n\n\nimport ipywidgets as widgets\noutput3 = widgets.Output()\noutput3\n\n\n\n\n\nprint(\"hi3\")\nwith output3:\n    print(\"hello\")\n    clear_output(wait=True)\n    print(\"world\")\n\nhi3\n\n\n\nimport ipywidgets as widgets\noutput4 = widgets.Output()\noutput4\n\n\n\n\n\nprint(\"hi4\")\nwith output4:\n    print(\"hello world\")\n    clear_output()\n\nhi4\n\n\n\nimport ipywidgets as widgets\noutput5 = widgets.Output()\noutput5\n\n\n\n\n\nprint(\"hi5\")\nwith output5:\n    display(\"hello world\") # this is not a stream but plain text\nclear_output()\n\n\nimport ipywidgets as widgets\noutput_outer = widgets.Output()\noutput_inner = widgets.Output()\noutput_inner\n\n\n\n\n\noutput_outer\n\n\n\n\n\nwith output_inner:\n    print('in inner')\n    with output_outer:\n        print('in outer')\n    print('also in inner')"
  },
  {
    "objectID": "my_env/lib/python3.10/site-packages/nbclient/tests/files/Skip Exceptions with Cell Tags.html",
    "href": "my_env/lib/python3.10/site-packages/nbclient/tests/files/Skip Exceptions with Cell Tags.html",
    "title": "Documenting my R/Python learning journey",
    "section": "",
    "text": "print('ok')\n\nok"
  },
  {
    "objectID": "my_env/lib/python3.10/site-packages/nbclient/tests/files/Interrupt.html",
    "href": "my_env/lib/python3.10/site-packages/nbclient/tests/files/Interrupt.html",
    "title": "Documenting my R/Python learning journey",
    "section": "",
    "text": "print(\"done\")\n\ndone"
  },
  {
    "objectID": "my_env/lib/python3.10/site-packages/nbclient/tests/files/Factorials.html",
    "href": "my_env/lib/python3.10/site-packages/nbclient/tests/files/Factorials.html",
    "title": "Documenting my R/Python learning journey",
    "section": "",
    "text": "for m in range(10):\n    i, j = j, i + j\n    print(j)\n\n2\n3\n5\n8\n13\n21\n34\n55\n89\n144"
  },
  {
    "objectID": "my_env/lib/python3.10/site-packages/nbclient/tests/files/Error.html",
    "href": "my_env/lib/python3.10/site-packages/nbclient/tests/files/Error.html",
    "title": "Documenting my R/Python learning journey",
    "section": "",
    "text": "0/0\n\nZeroDivisionError: division by zero"
  },
  {
    "objectID": "my_env/lib/python3.10/site-packages/nbclient/tests/files/Empty Cell.html",
    "href": "my_env/lib/python3.10/site-packages/nbclient/tests/files/Empty Cell.html",
    "title": "Documenting my R/Python learning journey",
    "section": "",
    "text": "\"Code 1\"\n\n'Code 1'\n\n\n\n\"Code 2\"\n\n'Code 2'"
  },
  {
    "objectID": "my_env/lib/python3.10/site-packages/nbclient/tests/files/Inline Image.html",
    "href": "my_env/lib/python3.10/site-packages/nbclient/tests/files/Inline Image.html",
    "title": "Documenting my R/Python learning journey",
    "section": "",
    "text": "Image('python.png')"
  },
  {
    "objectID": "my_env/lib/python3.10/site-packages/nbclient/tests/files/Skip Execution with Cell Tag.html",
    "href": "my_env/lib/python3.10/site-packages/nbclient/tests/files/Skip Execution with Cell Tag.html",
    "title": "Documenting my R/Python learning journey",
    "section": "",
    "text": "print('ok')\n\nok"
  },
  {
    "objectID": "my_env/lib/python3.10/site-packages/nbclient/tests/files/Clear Output.html",
    "href": "my_env/lib/python3.10/site-packages/nbclient/tests/files/Clear Output.html",
    "title": "Documenting my R/Python learning journey",
    "section": "",
    "text": "for i in range(10):\n    clear_output()\n    print(i)\n\n9\n\n\n\nprint(\"Hello world\")\nclear_output()\n\n\nprint(\"Hello world\", end='')\nclear_output(wait=True)  # no output after this\n\nHello world\n\n\n\nprint(\"Hello\", end='')\nclear_output(wait=True)  # here we have new output after wait=True\nprint(\"world\", end='')\n\nworld\n\n\n\nhandle0 = display(\"Hello world\", display_id=\"id0\")\n\n'Hello world'\n\n\n\nhandle1 = display(\"Hello\", display_id=\"id1\")\n\n'world'\n\n\n\nhandle1.update('world')\n\n\nhandle2 = display(\"Hello world\", display_id=\"id2\")\nclear_output()  # clears all output, also with display_ids\n\n\nhandle3 = display(\"Hello world\", display_id=\"id3\")\nclear_output(wait=True)\n\n'Hello world'\n\n\n\nhandle4 = display(\"Hello\", display_id=\"id4\")\nclear_output(wait=True)\nprint('world', end='')\n\nworld\n\n\n\nhandle4.update('Hello world')  # it is cleared, so it should not show up in the above cell"
  },
  {
    "objectID": "my_env/lib/python3.10/site-packages/soupsieve-2.3.2.post1.dist-info/license_files/LICENSE.html",
    "href": "my_env/lib/python3.10/site-packages/soupsieve-2.3.2.post1.dist-info/license_files/LICENSE.html",
    "title": "Documenting my R/Python learning journey",
    "section": "",
    "text": "Copyright (c) 2018 - 2022 Isaac Muse isaacmuse@gmail.com\nPermission is hereby granted, free of charge, to any person obtaining a copy of this software and associated documentation files (the “Software”), to deal in the Software without restriction, including without limitation the rights to use, copy, modify, merge, publish, distribute, sublicense, and/or sell copies of the Software, and to permit persons to whom the Software is furnished to do so, subject to the following conditions:\nThe above copyright notice and this permission notice shall be included in all copies or substantial portions of the Software.\nTHE SOFTWARE IS PROVIDED “AS IS”, WITHOUT WARRANTY OF ANY KIND, EXPRESS OR IMPLIED, INCLUDING BUT NOT LIMITED TO THE WARRANTIES OF MERCHANTABILITY, FITNESS FOR A PARTICULAR PURPOSE AND NONINFRINGEMENT. IN NO EVENT SHALL THE AUTHORS OR COPYRIGHT HOLDERS BE LIABLE FOR ANY CLAIM, DAMAGES OR OTHER LIABILITY, WHETHER IN AN ACTION OF CONTRACT, TORT OR OTHERWISE, ARISING FROM, OUT OF OR IN CONNECTION WITH THE SOFTWARE OR THE USE OR OTHER DEALINGS IN THE SOFTWARE."
  },
  {
    "objectID": "my_env/lib/python3.10/site-packages/nbformat-5.6.1.dist-info/licenses/COPYING.html",
    "href": "my_env/lib/python3.10/site-packages/nbformat-5.6.1.dist-info/licenses/COPYING.html",
    "title": "Documenting my R/Python learning journey",
    "section": "",
    "text": "This project is licensed under the terms of the Modified BSD License (also known as New or Revised or 3-Clause BSD), as follows:\n\nCopyright (c) 2001-2015, IPython Development Team\nCopyright (c) 2015-, Jupyter Development Team\n\nAll rights reserved.\nRedistribution and use in source and binary forms, with or without modification, are permitted provided that the following conditions are met:\nRedistributions of source code must retain the above copyright notice, this list of conditions and the following disclaimer.\nRedistributions in binary form must reproduce the above copyright notice, this list of conditions and the following disclaimer in the documentation and/or other materials provided with the distribution.\nNeither the name of the Jupyter Development Team nor the names of its contributors may be used to endorse or promote products derived from this software without specific prior written permission.\nTHIS SOFTWARE IS PROVIDED BY THE COPYRIGHT HOLDERS AND CONTRIBUTORS “AS IS” AND ANY EXPRESS OR IMPLIED WARRANTIES, INCLUDING, BUT NOT LIMITED TO, THE IMPLIED WARRANTIES OF MERCHANTABILITY AND FITNESS FOR A PARTICULAR PURPOSE ARE DISCLAIMED. IN NO EVENT SHALL THE COPYRIGHT OWNER OR CONTRIBUTORS BE LIABLE FOR ANY DIRECT, INDIRECT, INCIDENTAL, SPECIAL, EXEMPLARY, OR CONSEQUENTIAL DAMAGES (INCLUDING, BUT NOT LIMITED TO, PROCUREMENT OF SUBSTITUTE GOODS OR SERVICES; LOSS OF USE, DATA, OR PROFITS; OR BUSINESS INTERRUPTION) HOWEVER CAUSED AND ON ANY THEORY OF LIABILITY, WHETHER IN CONTRACT, STRICT LIABILITY, OR TORT (INCLUDING NEGLIGENCE OR OTHERWISE) ARISING IN ANY WAY OUT OF THE USE OF THIS SOFTWARE, EVEN IF ADVISED OF THE POSSIBILITY OF SUCH DAMAGE.\n\n\nThe Jupyter Development Team is the set of all contributors to the Jupyter project. This includes all of the Jupyter subprojects.\nThe core team that coordinates development on GitHub can be found here: https://github.com/jupyter/.\n\n\n\nJupyter uses a shared copyright model. Each contributor maintains copyright over their contributions to Jupyter. But, it is important to note that these contributions are typically only changes to the repositories. Thus, the Jupyter source code, in its entirety is not the copyright of any single person or institution. Instead, it is the collective copyright of the entire Jupyter Development Team. If individual contributors want to maintain a record of what changes/contributions they have specific copyright on, they should indicate their copyright in the commit message of the change, when they commit the change to one of the Jupyter repositories.\nWith this in mind, the following banner should be used in any source code file to indicate the copyright and license terms:\n# Copyright (c) Jupyter Development Team.\n# Distributed under the terms of the Modified BSD License."
  },
  {
    "objectID": "my_env/lib/python3.10/site-packages/jupyter_core-4.11.1.dist-info/license_files/COPYING.html",
    "href": "my_env/lib/python3.10/site-packages/jupyter_core-4.11.1.dist-info/license_files/COPYING.html",
    "title": "Documenting my R/Python learning journey",
    "section": "",
    "text": "Jupyter is licensed under the terms of the Modified BSD License (also known as New or Revised or 3-Clause BSD), as follows:\n\nCopyright (c) 2015-, Jupyter Development Team\n\nAll rights reserved.\nRedistribution and use in source and binary forms, with or without modification, are permitted provided that the following conditions are met:\nRedistributions of source code must retain the above copyright notice, this list of conditions and the following disclaimer.\nRedistributions in binary form must reproduce the above copyright notice, this list of conditions and the following disclaimer in the documentation and/or other materials provided with the distribution.\nNeither the name of the Jupyter Development Team nor the names of its contributors may be used to endorse or promote products derived from this software without specific prior written permission.\nTHIS SOFTWARE IS PROVIDED BY THE COPYRIGHT HOLDERS AND CONTRIBUTORS “AS IS” AND ANY EXPRESS OR IMPLIED WARRANTIES, INCLUDING, BUT NOT LIMITED TO, THE IMPLIED WARRANTIES OF MERCHANTABILITY AND FITNESS FOR A PARTICULAR PURPOSE ARE DISCLAIMED. IN NO EVENT SHALL THE COPYRIGHT OWNER OR CONTRIBUTORS BE LIABLE FOR ANY DIRECT, INDIRECT, INCIDENTAL, SPECIAL, EXEMPLARY, OR CONSEQUENTIAL DAMAGES (INCLUDING, BUT NOT LIMITED TO, PROCUREMENT OF SUBSTITUTE GOODS OR SERVICES; LOSS OF USE, DATA, OR PROFITS; OR BUSINESS INTERRUPTION) HOWEVER CAUSED AND ON ANY THEORY OF LIABILITY, WHETHER IN CONTRACT, STRICT LIABILITY, OR TORT (INCLUDING NEGLIGENCE OR OTHERWISE) ARISING IN ANY WAY OUT OF THE USE OF THIS SOFTWARE, EVEN IF ADVISED OF THE POSSIBILITY OF SUCH DAMAGE.\n\n\nThe Jupyter Development Team is the set of all contributors to the Jupyter project. This includes all of the Jupyter subprojects. A full list with details is kept in the documentation directory, in the file about/credits.txt.\nThe core team that coordinates development on GitHub can be found here: https://github.com/ipython/.\n\n\n\nJupyter uses a shared copyright model. Each contributor maintains copyright over their contributions to Jupyter. It is important to note that these contributions are typically only changes to the repositories. Thus, the Jupyter source code in its entirety is not the copyright of any single person or institution. Instead, it is the collective copyright of the entire Jupyter Development Team. If individual contributors want to maintain a record of what changes/contributions they have specific copyright on, they should indicate their copyright in the commit message of the change, when they commit the change to one of the Jupyter repositories.\nWith this in mind, the following banner should be used in any source code file to indicate the copyright and license terms:\n# Copyright (c) Jupyter Development Team.\n# Distributed under the terms of the Modified BSD License."
  },
  {
    "objectID": "posts/markov_chains/index.html",
    "href": "posts/markov_chains/index.html",
    "title": "Markov Chains",
    "section": "",
    "text": "Introduction to Markov Chains\nA Markov chain is a random process with the Markov property. A random process or often called stochastic property is a mathematical object defined as a collection of random variables. A Markov chain has either discrete state space (set of possible values of the random variables) or discrete index set (often representing time) - given the fact, many variations for a Markov chain exists. Usually the term “Markov chain” is reserved for a process with a discrete set of times, that is a Discrete Time Markov chain (DTMC).\nTo develop better intuition about Markov chain, the simpler version of it is to model a basic random walk."
  },
  {
    "objectID": "posts/markov_chains/index.html#from-scratch",
    "href": "posts/markov_chains/index.html#from-scratch",
    "title": "Markov Chains",
    "section": "From scratch",
    "text": "From scratch\n\nimport numpy as np\n\nstart = 0\ny = []\nn = 1000\n\nfor i in range(n): \n  step = np.random.choice([-1, 1], p = [0.5, 0.5])\n  start += step\n  y.append(start)\n\n\nimport matplotlib.pyplot as plt\n\nplt.plot(y)\n#plt.xlabel('Number of steps')\n#plt.ylabel(r'$S_{n}$')\n\n\n\n\nA random walk with a 1000 steps and equal probabilty to go left or right"
  },
  {
    "objectID": "posts/markov_chains/index.html#using-financial-data",
    "href": "posts/markov_chains/index.html#using-financial-data",
    "title": "Markov Chains",
    "section": "Using financial data",
    "text": "Using financial data\nPython code coming from this post\nA Monte-Carlo simulation of a random-walk of a stock price does assume that the returns follow a normal distribution. A second assumption is that the past volatility of returns will continue (or be very similar) in the future. This is of course not totally the case.\n\nGetting data and feature engineeriing\nGetting data using the yfinance package.\n\nimport yfinance as yf\nimport pandas as pd\n\nyo = yf.download(\"SBUX\", start = \"2005-01-01\")\n\nyo.to_csv(\"../../raw_data/sbux.csv\")\n\nyo['Adj Close'][-1]\n\nyo.info()\n\nWe have imported SBUX stock price data and stored them on disk. We’ll retrieve it using pandas and construct our returns and volatility variables.\n\nimport pandas as pd\n\nsbux = pd.read_csv(\"../../raw_data/sbux.csv\")\n\nsbux.tail() \n\n# get the daily returns and then filter on the last 2 years of trading. \n# calculate volatiliy on these last years (not realistic of course)\ndaily_returns = sbux['Adj Close'].pct_change()\n#sbux = sbux.tail(505)\ndaily_volat = daily_returns.std()\n\nprint(daily_volat)\n\nsbux.info()\n\n0.01948403159171024\n<class 'pandas.core.frame.DataFrame'>\nRangeIndex: 4483 entries, 0 to 4482\nData columns (total 7 columns):\n #   Column     Non-Null Count  Dtype  \n---  ------     --------------  -----  \n 0   Date       4483 non-null   object \n 1   Open       4483 non-null   float64\n 2   High       4483 non-null   float64\n 3   Low        4483 non-null   float64\n 4   Close      4483 non-null   float64\n 5   Adj Close  4483 non-null   float64\n 6   Volume     4483 non-null   int64  \ndtypes: float64(5), int64(1), object(1)\nmemory usage: 245.3+ KB\n\n\n\n\nSingle simulation\n\nimport numpy as np\nimport matplotlib.pyplot as plt\n\nlook_back = 252 \ncount = 0\nprice_list = []\nlast_price = sbux['Adj Close'].iloc[-1]\n\nprice = last_price * (1 + np.random.normal(0, daily_volat)) \nprice_list.append(price)\n\nfor y in range(look_back): \n  if count == 251: \n    break\n  price = price_list[count] * (1 + np.random.normal(0, daily_volat))\n  price_list.append(price) \n  count += 1\n  \nplt.plot(price_list)\nplt.show()\n\n#price_list\n\n\n\n\nAn here would be another single simulation. It will of course look vastly different although it is build from the same normal distribution with same mean $ = 0$ and sd $ = 0$.\n\n\n\n\n\nNow we can re-use that code if we want to create 100’s of these simulations.\n\nnum_of_simulations = 10 \nmodel_ahead = 252 \n\ndf = pd.DataFrame()\nlast_price_list = []\n\nfor x in range(num_of_simulations): \n  count = 0\n  price_list = []\n  last_price = sbux.iloc[-1]['Adj Close'] \n  price = last_price * (1 + np.random.normal(0, daily_volat)) \n  price_list.append(price) \n  \n  for y in range(model_ahead): \n    if count == 251: \n      break\n    price = price_list[count] * (1 + np.random.normal(0, daily_volat)) \n    price_list.append(price) \n    count += 1\n  \n  df[x] = price_list\n  last_price_list.append(price_list[-1])\n    \n  \nfig = plt.figure()\nfig.suptitle(\"Monte Carlo Simulation for SBUX\") \nplt.plot(df)\nplt.xlabel(\"Day\")\nplt.ylabel(\"Price\")\nplt.show()\n\n\n\n\nWith just 10 simulated random-walks on SBUX given the last 17 years of volatility, we can see that price could range between $40 to around $140 dollars over the next 252 trading days (one year).\n\n\nAnalysis of our MC simulation\n\nprint(\"Expected price: \", round(np.mean(last_price_list), 2))\nprint(\"Quantile (5%): \", np.percentile(last_price_list, 5))\nprint(\"Quantile (95%): \", np.percentile(last_price_list, 95))\n\nExpected price:  88.98\nQuantile (5%):  64.17020007230518\nQuantile (95%):  144.89853661740665\n\n\n\nplt.hist(last_price_list, bins=10) \nplt.show()"
  },
  {
    "objectID": "posts/markov_chains/index.html#transition-matrix",
    "href": "posts/markov_chains/index.html#transition-matrix",
    "title": "Markov Chains",
    "section": "Transition Matrix",
    "text": "Transition Matrix\nIn a transition matrix, the rows are you starting state and columns are your end of state.\nSo with the below matrix, the probability to go from state A to state A is 0.8 and probability to go from state A to state D is 0.2. In this sense, all the rows of a transition matrix should always add up to 1.\n\nstate_A = [0.1, 0.4, 0.3, 0.2, 0]\nstate_B = [0.0, 0.5, 0.5, 0.0, 0]\nstate_C = [0.0, 0.0, 1.0, 0.0, 0]\nstate_D = [0.0, 0.0, 0.0, 0.0, 1.0]\nstate_E = [0.0, 0.0, 0.0, 0.5, 0.5]\n\ntransition_matrix = [state_A, state_B, state_C, state_D, state_E]\n\nWe could also create a function to check if a transition matrix is indeed a properly formatted transition matrix to model a markov chain.\n\ndef check_markov_chain(m): \n  for i in range(0, len(m)): \n    if sum(m[i]) != 1: \n      return False\n  print(\"This is a correlty formatted transition matrix\") \n  \ncheck_markov_chain(transition_matrix)\n\nThis is a correlty formatted transition matrix"
  },
  {
    "objectID": "posts/kmeans/index.html",
    "href": "posts/kmeans/index.html",
    "title": "Kmeans with regime changes",
    "section": "",
    "text": "This post is about how to use Kmeans to classify various market regimes or to use kmeans to classifiy financial observations.\nWith K-means we are trying to establish groups of data that are homegenous and distinctly different from other groups. The K- stands for the number of clusters we will create.\nThe concept of distance comes in when deciding if a data point belongs to a cluster. The most common way to measure distance is the Euclidean Distance.\nWith multivariate data set, it is important to normalize the data.\nA usual rule of thumb is to set the number of clusters as the square root of the number of observation."
  },
  {
    "objectID": "posts/kmeans/index.html#load-up-packages-and-read-data",
    "href": "posts/kmeans/index.html#load-up-packages-and-read-data",
    "title": "Kmeans with regime changes",
    "section": "Load up packages and read data",
    "text": "Load up packages and read data\n\nlibrary(readr)        # load and read .csv file\nlibrary(glue)         # concatenate strings together\nlibrary(dplyr)        # the tidy plyr tool for data wrangling\nlibrary(tidyr)        # to use the drop_na function\n\nthe_path <- here::here()\n\ndf <- read_csv(glue(the_path, \"/raw_data/intc.csv\")) |> \n  rename(date = Date, high = High, low = Low, close = Close, adj_close = 'Adj Close') |> \n  select(date, high, low, close, adj_close)\nglimpse(df)\n\nRows: 10,738\nColumns: 5\n$ date      <dttm> 1980-03-17 05:00:00, 1980-03-18 05:00:00, 1980-03-19 05:00:…\n$ high      <dbl> 0.330729, 0.328125, 0.335938, 0.334635, 0.322917, 0.316406, …\n$ low       <dbl> 0.325521, 0.322917, 0.330729, 0.329427, 0.317708, 0.311198, …\n$ close     <dbl> 0.325521, 0.322917, 0.330729, 0.329427, 0.317708, 0.311198, …\n$ adj_close <dbl> 0.1907656, 0.1892397, 0.1938177, 0.1930547, 0.1861870, 0.182…"
  },
  {
    "objectID": "posts/kmeans/index.html#feature-engineering",
    "href": "posts/kmeans/index.html#feature-engineering",
    "title": "Kmeans with regime changes",
    "section": "Feature engineering",
    "text": "Feature engineering\n\nlibrary(TTR)      # The technical analysis package\n\nyo <- aroon(df[, c('high', 'low')], n = 23)\ndf$aroon <- yo[, 3]\nyo <- CCI(df[, c('high', 'low', 'close')], n = 17)\ndf$cci <- yo\nyo <- chaikinVolatility(df[, c('high', 'low')], n = 13)\ndf$chaikinVol <- yo\n\ndf1 <- df |> \n  select(date, aroon, cci, chaikinVol, adj_close) |> \n  mutate(across(c(aroon, cci, chaikinVol), ~ as.numeric(scale(.)))) |>\n  drop_na()\n\nskimr::skim(df1 %>% select(-date))\n\n\nData summary\n\n\nName\ndf1 %>% select(-date)\n\n\nNumber of rows\n10713\n\n\nNumber of columns\n4\n\n\n_______________________\n\n\n\nColumn type frequency:\n\n\n\nnumeric\n4\n\n\n________________________\n\n\n\nGroup variables\nNone\n\n\n\nVariable type: numeric\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nskim_variable\nn_missing\ncomplete_rate\nmean\nsd\np0\np25\np50\np75\np100\nhist\n\n\n\n\naroon\n0\n1\n0.00\n1.00\n-1.70\n-0.95\n0.29\n0.91\n1.46\n▆▆▂▇▇\n\n\ncci\n0\n1\n0.00\n1.00\n-4.30\n-0.80\n0.06\n0.78\n3.87\n▁▃▇▅▁\n\n\nchaikinVol\n0\n1\n0.00\n1.00\n-2.42\n-0.62\n-0.14\n0.42\n12.71\n▇▂▁▁▁\n\n\nadj_close\n0\n1\n14.89\n15.23\n0.13\n0.77\n12.90\n19.88\n65.25\n▇▅▁▁▁\n\n\n\n\n# also good to check for correlation between variables. \nlibrary(corrr)\ndf1 |> select(-date, -adj_close) |> \n  correlate() |> \n  rearrange() |> \n  shave()\n\n# A tibble: 3 × 4\n  term            cci   aroon chaikinVol\n  <chr>         <dbl>   <dbl>      <dbl>\n1 cci        NA       NA              NA\n2 aroon       0.567   NA              NA\n3 chaikinVol -0.00427  0.0211         NA\n\n\nThese 3 variables seem to complete each other well as little to-no correlation."
  },
  {
    "objectID": "posts/kmeans/index.html#create-clusters",
    "href": "posts/kmeans/index.html#create-clusters",
    "title": "Kmeans with regime changes",
    "section": "Create clusters",
    "text": "Create clusters\n\nlibrary(purrr)     #use the map function\nlibrary(broom)     #use the glance function on kmeans \ndf1sc <- df1 %>% select(-date, -adj_close)\n\nkclusts <- tibble(k = 1:9) |> \n  mutate(kclust = map(k, ~kmeans(df1sc, centers = .x, iter.max = 50L)), \n         glanced = map(kclust, glance), \n         augmented = map(kclust, augment, df1))\n\nkclusts |> unnest(cols = c('glanced'))\n\n# A tibble: 9 × 7\n      k kclust    totss tot.withinss betweenss  iter augmented            \n  <int> <list>    <dbl>        <dbl>     <dbl> <int> <list>               \n1     1 <kmeans> 32127.       32127.  2.36e-10     1 <tibble [10,713 × 6]>\n2     2 <kmeans> 32127.       19719.  1.24e+ 4     1 <tibble [10,713 × 6]>\n3     3 <kmeans> 32127.       15887.  1.62e+ 4     5 <tibble [10,713 × 6]>\n4     4 <kmeans> 32127.       13538.  1.86e+ 4     4 <tibble [10,713 × 6]>\n5     5 <kmeans> 32127.       11165.  2.10e+ 4     5 <tibble [10,713 × 6]>\n6     6 <kmeans> 32127.        9921.  2.22e+ 4     4 <tibble [10,713 × 6]>\n7     7 <kmeans> 32127.        8508.  2.36e+ 4     5 <tibble [10,713 × 6]>\n8     8 <kmeans> 32127.        7978.  2.41e+ 4     6 <tibble [10,713 × 6]>\n9     9 <kmeans> 32127.        7250.  2.49e+ 4     6 <tibble [10,713 × 6]>\n\n\nThere are several ways to choose the ideal number of clusters. One of them is the elbow method, another one is the Silhouette Method.\nThe tot.withinss is the total within-cluster sum of square. This is the value used for the eblow method.\nFor the Silhouette Method, we can use the cluster package.\n\navg_sil <- function(k) { \n  kmeans_object <- kmeans(df1sc, centers = k, iter.max = 50L)\n  silh = cluster::silhouette(kmeans_object$cluster, dist(df1sc))\n  mean(silh[, 3])\n  }\n\n# Compute and plot wss for k = 2 to k = 15\nyo <- tibble(k_values =  2:9) |> \n  mutate(avg_sil_values = map_dbl(k_values, avg_sil))\n\nyo\n\n# A tibble: 8 × 2\n  k_values avg_sil_values\n     <int>          <dbl>\n1        2          0.376\n2        3          0.369\n3        4          0.307\n4        5          0.312\n5        6          0.309\n6        7          0.307\n7        8          0.298\n8        9          0.280\n\n\nA more elegant way to do that, using this post from SO\n\nyo <- kclusts |> \n  mutate(silhouetted = map(augmented, ~ cluster::silhouette(as.numeric(levels(.x$.cluster))[.x$.cluster], dist(df1sc)))) |> \n  select(k, silhouetted) |> unnest(cols=c('silhouetted')) |> \n  group_by(k) %>% \n  summarise(avg_sil_values = mean(silhouetted[,3]))\n\nyo\n\n# A tibble: 9 × 2\n      k avg_sil_values\n  <int>          <dbl>\n1     1         NA    \n2     2          0.376\n3     3          0.369\n4     4          0.307\n5     5          0.292\n6     6          0.309\n7     7          0.307\n8     8          0.294\n9     9          0.280"
  },
  {
    "objectID": "posts/kmeans/index.html#some-visualizations",
    "href": "posts/kmeans/index.html#some-visualizations",
    "title": "Kmeans with regime changes",
    "section": "Some visualizations",
    "text": "Some visualizations\n\nElbow method\n\nlibrary(ggplot2)\nkclusts |> \n  unnest(cols = c('glanced')) |> \n  ggplot(aes(k, tot.withinss)) + \n  geom_line(alpha = 0.5, size = 1.2, color = 'midnightblue') + \n  geom_point(size = 2, color = 'midnightblue')\n\n\n\n\nTotal within-cluster sum of square for k-cluster\n\n\n\n\nBased on the elbow method, I would be tempted to choose to 5 clusters (2 seems another obvious one).\n\n\nSilhouette Method\n\nyo |> ggplot(aes(k, avg_sil_values)) + \n  geom_line(alpha = 0.5, size = 1.2, color = 'midnightblue') + \n  geom_point(size = 2, color = 'midnightblue')\n\nWarning: Removed 1 row(s) containing missing values (geom_path).\n\n\nWarning: Removed 1 rows containing missing values (geom_point).\n\n\n\n\n\nSilhouette score for k-clusters\n\n\n\n\n2 is the winner ;-)\n\n\nPlotting the stocks with clustered observations\n\nlibrary(lubridate)\nyo <- kmeans(df1 |> select(-date, -adj_close), centers = 2)\naugment(yo, df1) |> filter(date >= today() - 500) |> \n  ggplot(aes(x = date, y = adj_close)) + \n    geom_line(alpha = 0.5, color = 'midnightblue') + \n    geom_point(aes(color = .cluster)) + \n    theme(legend.position = 'none')\n\n\n\n\nPlotting adjusted close price with only 2 clusters\n\n\n\n\n\nyo <- kmeans(df1 |> select(-date, -adj_close), centers = 3)\naugment(yo, df1) |> filter(date >= today() - 500) |> \n  ggplot(aes(x = date, y = adj_close)) + \n    geom_line(alpha = 0.5, color = 'midnightblue') + \n    geom_point(aes(color = .cluster)) + \n    theme(legend.position = 'none')\n\n\n\n\nPlotting adjusted close price with only 3 clusters\n\n\n\n\n\nyo <- kmeans(df1 |> select(-date, -adj_close), centers = 6)\naugment(yo, df1) |> filter(date >= today() - 500) |> \n  ggplot(aes(x = date, y = adj_close)) + \n    geom_line(alpha = 0.5, color = 'midnightblue') + \n    geom_point(aes(color = .cluster)) + \n    theme(legend.position = 'none')\n\n\n\n\nPlotting adjusted close price with only 6 clusters"
  },
  {
    "objectID": "posts/welcome/index.html",
    "href": "posts/welcome/index.html",
    "title": "Welcome To My Blog",
    "section": "",
    "text": "Since this post doesn’t specify an explicit image, the first image in the post will be used in the listing page of posts."
  },
  {
    "objectID": "posts/extrapolate-wtih-decision-tree/index.html",
    "href": "posts/extrapolate-wtih-decision-tree/index.html",
    "title": "Extrapolate with Decision Trees",
    "section": "",
    "text": "The idea of this document is to show how Xgboost can be especially bad at extrapolating or make prediction out of range of given data. This idea of this post come from this blog"
  },
  {
    "objectID": "posts/extrapolate-wtih-decision-tree/index.html#using-r",
    "href": "posts/extrapolate-wtih-decision-tree/index.html#using-r",
    "title": "Extrapolate with Decision Trees",
    "section": "Using R",
    "text": "Using R\n\nlibrary(tibble)\nlibrary(dplyr)\nlibrary(ggplot2)\nlibrary(parsnip)\n\nset.seed(123)\ndf <- tibble(t = seq(1:100), \n             y = t + 2 * rnorm(100, mean = 0, sd = 1))\n\n#The first 50 observation to be used for training and the last 50 for testing.\ndf_train <- df[1:50, ]\ndf_test <- df[51:100, ]\n\nmodel = decision_tree(mode = \"regression\", engine = \"rpart\", tree_depth = 2) \nmodel_fit = model %>% fit(y ~ t, data = df_train)\nmodel_fit\n\nparsnip model object\n\nn= 50 \n\nnode), split, n, deviance, yval\n      * denotes terminal node\n\n1) root 50 10523.98000 25.568810  \n  2) t< 26.5 26  1260.25700 13.306160  \n    4) t< 10.5 10    88.19884  5.649251 *\n    5) t>=10.5 16   219.34920 18.091720 *\n  3) t>=26.5 24  1118.54600 38.853340  \n    6) t< 41.5 15   255.91590 34.484340 *\n    7) t>=41.5 9    99.10379 46.135010 *\n\ny_predict <- add_row(predict(model_fit, df_train),  predict(model_fit, df_test) )\n\ndf <- df |> add_column( y_predict)\ntail(df)\n\n# A tibble: 6 × 3\n      t     y .pred\n  <int> <dbl> <dbl>\n1    95  97.7  46.1\n2    96  94.8  46.1\n3    97 101.   46.1\n4    98 101.   46.1\n5    99  98.5  46.1\n6   100  97.9  46.1\n\nggplot() + \n  geom_line(aes(x = t, y = y, color = \"a\"), data = df[1:50, ], show.legend = TRUE) + \n  geom_line(aes(x = t, y = y, color=\"a\"), lty=2, data = df[50:100, ]) + \n  geom_line(aes(x=t, y = .pred, color = \"b\"), data = df[1:50, ]) + \n  geom_line(aes(x = t, y = .pred, color = \"c\"), lty=2, data = df[50:100, ]) + \n  scale_color_manual(name = \"Legend\", \n                     values = c(\"a\" = \"blue\", \"b\" = \"red\", \"c\" = \"purple\"), \n                     labels = c(\"Data\", \"In sample testing\", \"Out of sample testing\")) + \n  theme(legend.position = \"bottom\")\n\n\n\n\nFigure 1: Performance of decision tree on a linear trend"
  },
  {
    "objectID": "posts/xgboost_time_series/index.html",
    "href": "posts/xgboost_time_series/index.html",
    "title": "Translating Python Part 1 - Xgboost with Time-Series",
    "section": "",
    "text": "This post is about using xgboost on a time-series using both R with the tidymodel framework and python. It is part of a series of articles aiming at translating python timeseries blog articles into their tidymodels equivalent.\nThe raw data is quite simple as it is energy consumption based on an hourly consumption. Original article can be found here. Mimimal changes were made to better fit current python practices.\nXgboost is part of the ensemble machine learning algorithms. It can be used for both regression and classification. There are few issues in using xgboost with time-series. This article is taking a Xgboost post in python and also translating with the new R tidymodel framework."
  },
  {
    "objectID": "posts/xgboost_time_series/index.html#using-r",
    "href": "posts/xgboost_time_series/index.html#using-r",
    "title": "Translating Python Part 1 - Xgboost with Time-Series",
    "section": "Using R",
    "text": "Using R\n\n# setting up main R libraries to start \nthe_path <- here::here()\nlibrary(glue)\nlibrary(readr)\nlibrary(dplyr)\nlibrary(ggplot2)\n\ndf0 <- read_csv(glue(the_path, \"/raw_data/AEP_hourly.csv\"))\n\n# let's have a quick look at what we are dealing with\nglimpse(df0)\n\nRows: 121,273\nColumns: 2\n$ Datetime <dttm> 2004-12-31 01:00:00, 2004-12-31 02:00:00, 2004-12-31 03:00:0…\n$ AEP_MW   <dbl> 13478, 12865, 12577, 12517, 12670, 13038, 13692, 14297, 14719…\n\n\nThere are only 2 variables. The Datetime being the only independ variable. And the energy consumption labelled as AEP_MW being our variable to predict.\n\n# and graphically - \n# just using a couple of years to get an idea \nggplot(df0 |> filter(Datetime > \"2014-01-01\" & Datetime < \"2016-01-01\"), aes(x =Datetime, y=AEP_MW )) + geom_line(color = \"light blue\")\n\n\n\n\nFigure 1: Graphical glimpse of our raw data\n\n\n\n\nAs Datetime is our only input variable, we’ll use the usual tricks of breaking it down into week number, months, etc. I am doing it slightly differently than in the python version here as I will first create the new time related variables then I will split it into training and testing.\n\nlibrary(lubridate)\ndf <- df0 |> \n  mutate(hour = hour(Datetime), \n         day_of_week = wday(Datetime), \n         day_of_year = yday(Datetime), \n         day_of_month = mday(Datetime), \n         week_of_year = isoweek(Datetime), \n         month = month(Datetime), \n         quarter = quarter(Datetime), \n         year = isoyear(Datetime)\n         ) \n\n# another glimpse now. \nglimpse(df)\n\nRows: 121,273\nColumns: 10\n$ Datetime     <dttm> 2004-12-31 01:00:00, 2004-12-31 02:00:00, 2004-12-31 03:…\n$ AEP_MW       <dbl> 13478, 12865, 12577, 12517, 12670, 13038, 13692, 14297, 1…\n$ hour         <int> 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17…\n$ day_of_week  <dbl> 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, …\n$ day_of_year  <dbl> 366, 366, 366, 366, 366, 366, 366, 366, 366, 366, 366, 36…\n$ day_of_month <int> 31, 31, 31, 31, 31, 31, 31, 31, 31, 31, 31, 31, 31, 31, 3…\n$ week_of_year <dbl> 53, 53, 53, 53, 53, 53, 53, 53, 53, 53, 53, 53, 53, 53, 5…\n$ month        <dbl> 12, 12, 12, 12, 12, 12, 12, 12, 12, 12, 12, 12, 12, 12, 1…\n$ quarter      <int> 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, …\n$ year         <dbl> 2004, 2004, 2004, 2004, 2004, 2004, 2004, 2004, 2004, 200…\n\n\nAlthough, there are only 2 variables, there are over 120,000 rows of data. That’s non-negligible."
  },
  {
    "objectID": "posts/xgboost_time_series/index.html#using-python",
    "href": "posts/xgboost_time_series/index.html#using-python",
    "title": "Translating Python Part 1 - Xgboost with Time-Series",
    "section": "Using python",
    "text": "Using python\nThis is the code from the original post.\n\nimport numpy as np\nimport pandas as pd\nimport matplotlib.pyplot as plt\n\npy_df = pd.read_csv(\"../../raw_data/AEP_hourly.csv\", index_col = [0], parse_dates = [0])\npy_df.tail()\n#plt.plot(df0)\n\n                      AEP_MW\nDatetime                    \n2018-01-01 20:00:00  21089.0\n2018-01-01 21:00:00  20999.0\n2018-01-01 22:00:00  20820.0\n2018-01-01 23:00:00  20415.0\n2018-01-02 00:00:00  19993.0\n\nsplit_date = '01-jan-2016'\npy_df_train = py_df.loc[py_df.index <= split_date].copy()\npy_df_test = py_df.loc[py_df.index > split_date].copy()\n\nThe author of the python blog first created a train / test set then created a function to add the variables then applied that function to both sets. This is a very valid way of doing things when steps include normalizing and/or scaling data before applying our ML algorithms as we don’t want any leakage from our training set into our testing set.\n\n# Create features of df\ndef create_features(df, label = None): \n  df['date'] = df.index \n  df['hour'] = df['date'].dt.hour\n  df['day_of_week'] = df['date'].dt.dayofweek\n  df['day_of_year'] = df['date'].dt.dayofyear \n  df['day_of_month'] = df['date'].dt.day \n  df['week_of_year'] = df['date'].dt.isocalendar().week \n  df['month'] = df['date'].dt.month \n  df['quarter'] = df['date'].dt.quarter \n  df['year'] = df['date'].dt.year\n  \n  X = df[['hour', 'day_of_week', 'day_of_year', 'day_of_month', 'week_of_year', 'month', 'quarter', 'year']]\n  \n  if label: \n    y = df[label]\n    return X, y\n  \n  return X\n\nCompare this way of constructing variables to the much easier and more elegant tidyverse’s way of cleaning and creating variables. The dplyr package really makes it painless to wrangle data."
  },
  {
    "objectID": "posts/xgboost_time_series/index.html#using-r-1",
    "href": "posts/xgboost_time_series/index.html#using-r-1",
    "title": "Translating Python Part 1 - Xgboost with Time-Series",
    "section": "Using R",
    "text": "Using R\nRsample is the tidymodel package that deals with creating training and testing sets. There are really many methods available to do this, but we stick to the same methods provided in the original blog post. There are out-of-the-box methods to deal with timeseries like in this case.\n\nlibrary(rsample)\n\nprop_split = 1 - (nrow(df |> filter(Datetime > \"2016-01-01\")) / nrow(df))\ndf_split <- initial_time_split(df |> arrange(Datetime), prop = prop_split)\n\ndf_train <- training(df_split)\ndf_test <- testing(df_split)"
  },
  {
    "objectID": "posts/xgboost_time_series/index.html#using-python-1",
    "href": "posts/xgboost_time_series/index.html#using-python-1",
    "title": "Translating Python Part 1 - Xgboost with Time-Series",
    "section": "Using Python",
    "text": "Using Python\n\npy_x_train, py_y_train = create_features(py_df_train, label = \"AEP_MW\")\npy_x_test, py_y_test =   create_features(py_df_test, label = \"AEP_MW\")\n\n#When running xgboost, I got an issue with one of the type of the variable.  \n# Let's fix this. \npy_x_train.info()\n\n<class 'pandas.core.frame.DataFrame'>\nDatetimeIndex: 98594 entries, 2004-12-31 01:00:00 to 2015-01-02 00:00:00\nData columns (total 8 columns):\n #   Column        Non-Null Count  Dtype \n---  ------        --------------  ----- \n 0   hour          98594 non-null  int64 \n 1   day_of_week   98594 non-null  int64 \n 2   day_of_year   98594 non-null  int64 \n 3   day_of_month  98594 non-null  int64 \n 4   week_of_year  98594 non-null  UInt32\n 5   month         98594 non-null  int64 \n 6   quarter       98594 non-null  int64 \n 7   year          98594 non-null  int64 \ndtypes: UInt32(1), int64(7)\nmemory usage: 6.5 MB\n\npy_x_train = py_x_train.astype(np.int64)\npy_x_test = py_x_test.astype(np.int64)\n\npy_x_train.info()\n\n<class 'pandas.core.frame.DataFrame'>\nDatetimeIndex: 98594 entries, 2004-12-31 01:00:00 to 2015-01-02 00:00:00\nData columns (total 8 columns):\n #   Column        Non-Null Count  Dtype\n---  ------        --------------  -----\n 0   hour          98594 non-null  int64\n 1   day_of_week   98594 non-null  int64\n 2   day_of_year   98594 non-null  int64\n 3   day_of_month  98594 non-null  int64\n 4   week_of_year  98594 non-null  int64\n 5   month         98594 non-null  int64\n 6   quarter       98594 non-null  int64\n 7   year          98594 non-null  int64\ndtypes: int64(8)\nmemory usage: 6.8 MB"
  },
  {
    "objectID": "posts/xgboost_time_series/index.html#using-r-2",
    "href": "posts/xgboost_time_series/index.html#using-r-2",
    "title": "Translating Python Part 1 - Xgboost with Time-Series",
    "section": "Using R",
    "text": "Using R\nAgain this is a very straightforward xgboost application to a dataset. No fine tuning of models, recipe, etc.\n\nlibrary(parsnip)\n\nmodel_xgboost <- boost_tree(stop_iter = 50L, trees=1000L) |> \n  set_engine(\"xgboost\") |>\n  set_mode(\"regression\")\n  \nfit_xgboost <- model_xgboost |> \n  fit(AEP_MW ~., data = df_train %>% select(-Datetime))\n\nfit_xgboost\n\nparsnip model object\n\n##### xgb.Booster\nraw: 4.7 Mb \ncall:\n  xgboost::xgb.train(params = list(eta = 0.3, max_depth = 6, gamma = 0, \n    colsample_bytree = 1, colsample_bynode = 1, min_child_weight = 1, \n    subsample = 1), data = x$data, nrounds = 1000L, watchlist = x$watchlist, \n    verbose = 0, early_stopping_rounds = 50L, nthread = 1, objective = \"reg:squarederror\")\nparams (as set within xgb.train):\n  eta = \"0.3\", max_depth = \"6\", gamma = \"0\", colsample_bytree = \"1\", colsample_bynode = \"1\", min_child_weight = \"1\", subsample = \"1\", nthread = \"1\", objective = \"reg:squarederror\", validate_parameters = \"TRUE\"\nxgb.attributes:\n  best_iteration, best_msg, best_ntreelimit, best_score, niter\ncallbacks:\n  cb.evaluation.log()\n  cb.early.stop(stopping_rounds = early_stopping_rounds, maximize = maximize, \n    verbose = verbose)\n# of features: 8 \nniter: 1000\nbest_iteration : 1000 \nbest_ntreelimit : 1000 \nbest_score : 242.3155 \nbest_msg : [1000]   training-rmse:242.315489 \nnfeatures : 8 \nevaluation_log:\n    iter training_rmse\n       1    11175.8839\n       2     7906.5875\n---                   \n     999      242.5272\n    1000      242.3155"
  },
  {
    "objectID": "posts/xgboost_time_series/index.html#using-python-2",
    "href": "posts/xgboost_time_series/index.html#using-python-2",
    "title": "Translating Python Part 1 - Xgboost with Time-Series",
    "section": "Using Python",
    "text": "Using Python\n\nfrom xgboost.sklearn import XGBRegressor\npy_xgboost_mod = XGBRegressor(n_estimator = 1000, early_stopping_rounds = 50)\n\npy_xgboost_mod.fit(py_x_train, py_y_train, \n                   eval_set = [(py_x_train, py_y_train), (py_x_test, py_y_test)], \n                   verbose = True)\n\nXGBRegressor(base_score=0.5, booster='gbtree', callbacks=None,\n             colsample_bylevel=1, colsample_bynode=1, colsample_bytree=1,\n             early_stopping_rounds=50, enable_categorical=False,\n             eval_metric=None, gamma=0, gpu_id=-1, grow_policy='depthwise',\n             importance_type=None, interaction_constraints='',\n             learning_rate=0.300000012, max_bin=256, max_cat_to_onehot=4,\n             max_delta_step=0, max_depth=6, max_leaves=0, min_child_weight=1,\n             missing=nan, monotone_constraints='()', n_estimator=1000,\n             n_estimators=100, n_jobs=0, num_parallel_tree=1, predictor='auto',\n             random_state=0, reg_alpha=0, ...)In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.XGBRegressorXGBRegressor(base_score=0.5, booster='gbtree', callbacks=None,\n             colsample_bylevel=1, colsample_bynode=1, colsample_bytree=1,\n             early_stopping_rounds=50, enable_categorical=False,\n             eval_metric=None, gamma=0, gpu_id=-1, grow_policy='depthwise',\n             importance_type=None, interaction_constraints='',\n             learning_rate=0.300000012, max_bin=256, max_cat_to_onehot=4,\n             max_delta_step=0, max_depth=6, max_leaves=0, min_child_weight=1,\n             missing=nan, monotone_constraints='()', n_estimator=1000,\n             n_estimators=100, n_jobs=0, num_parallel_tree=1, predictor='auto',\n             random_state=0, reg_alpha=0, ...)"
  },
  {
    "objectID": "posts/xgboost_time_series/index.html#using-r-3",
    "href": "posts/xgboost_time_series/index.html#using-r-3",
    "title": "Translating Python Part 1 - Xgboost with Time-Series",
    "section": "Using R",
    "text": "Using R\n2 ways to do this … (actually more than 2 ways, but here are 2 main ways.). First one is a straight table using the xgboost library itself.\n\nlibrary(xgboost)\nxgb.importance(model = fit_xgboost$fit)\n\n        Feature        Gain       Cover    Frequency\n1:  day_of_year 0.361828048 0.455387001 0.2800303942\n2:         hour 0.336852823 0.125331328 0.2374139102\n3:         year 0.120129969 0.129691117 0.2000679018\n4:  day_of_week 0.105250594 0.073258066 0.1489636887\n5: week_of_year 0.047083085 0.097216236 0.0462379151\n6: day_of_month 0.027801118 0.116483820 0.0864293336\n7:        month 0.001054362 0.002632432 0.0008568565\n\n#detach(xgboost)\n\nAnd also a graphic way.\n\nlibrary(vip)\n\nfit_xgboost %>%\n  vip(geom = \"point\")"
  },
  {
    "objectID": "posts/xgboost_time_series/index.html#using-python-3",
    "href": "posts/xgboost_time_series/index.html#using-python-3",
    "title": "Translating Python Part 1 - Xgboost with Time-Series",
    "section": "Using python",
    "text": "Using python\n\nfrom xgboost import plot_importance, plot_tree\n_ = plot_importance(py_xgboost_mod, height=0.9)\n\n\n\n\nI am a bit confused here in the output of the python graph with F-score vs the output of the R graph with importance."
  },
  {
    "objectID": "posts/xgboost_time_series/index.html#using-r-4",
    "href": "posts/xgboost_time_series/index.html#using-r-4",
    "title": "Translating Python Part 1 - Xgboost with Time-Series",
    "section": "Using R",
    "text": "Using R\nGraphing predicted power output vs actual power output could be a first way to see how our model fares in its predictions. So let’s graph our datetime vs power ouput for both actual and predicted.\n\nlibrary(tibble)  # for the add_column \nlibrary(parsnip)\n\ndf_test1 <- add_column(df_test,  predict(fit_xgboost, new_data = df_test)) \n\nggplot(df_test1, aes(x= Datetime, y = AEP_MW)) + \n  geom_line(color = \"blue\") + \n  geom_line(aes(y = .pred), color = \"yellow\", alpha = 0.5) + \n  labs(title = \"Energy Consumption in 2016-2018 (in MWh)\", y = \"Hourly consumption\")\n\n\n\n\nFigure 2: Actual Vs Predicted power consumption for 2016-2018\n\n\n\n\nWe can already see that we are not really modeling well the peaks and through.\nWe could get slightly more granular and try to see whats going on.\n\nggplot(df_test1 %>% filter(Datetime > \"2016-01-01\" & Datetime < \"2016-02-28\"), aes(x= Datetime, y = AEP_MW)) + \n  geom_line(color = \"blue\") + \n  geom_line(aes(y = .pred), color = \"yellow3\", alpha = 0.8)\n\n\n\n\nFigure 3: Actual Vs Predicted power consumption\n\n\n\n\nWe are clearly off there on the second half of February.\nNow, we can use the yardstick package to get numerical values to assess our model on the test set.\n\nlibrary(yardstick)\n\n# calculating the RMSE (root mean square error)\nrmse(df_test1, truth = AEP_MW, estimate = .pred, na_rm = TRUE)\n\n# A tibble: 1 × 3\n  .metric .estimator .estimate\n  <chr>   <chr>          <dbl>\n1 rmse    standard       2067.\n\n# calculating the MAE (mean absolute error)\nmae(df_test1, truth = AEP_MW, estimate = .pred)\n\n# A tibble: 1 × 3\n  .metric .estimator .estimate\n  <chr>   <chr>          <dbl>\n1 mae     standard       1495.\n\n# calculating the MAPE (mean absolute percent error)\nmape(df_test1, truth = AEP_MW, estimate = .pred)\n\n# A tibble: 1 × 3\n  .metric .estimator .estimate\n  <chr>   <chr>          <dbl>\n1 mape    standard        10.0\n\n# actually much easier to use the metric_set() function !\nxgboost_mod_metrics <- metric_set(rmse, mae, mape)\nxgboost_mod_metrics(df_test1, truth = AEP_MW, estimate = .pred) \n\n# A tibble: 3 × 3\n  .metric .estimator .estimate\n  <chr>   <chr>          <dbl>\n1 rmse    standard      2067. \n2 mae     standard      1495. \n3 mape    standard        10.0"
  },
  {
    "objectID": "posts/gini_coefficient/index.html",
    "href": "posts/gini_coefficient/index.html",
    "title": "Gini Coefficient of Impurity",
    "section": "",
    "text": "This article is to review one of the main way trees are being build. When deciding which node to split next, the Gini Coefficient of Impurity is being used."
  },
  {
    "objectID": "posts/post-with-code/index.html",
    "href": "posts/post-with-code/index.html",
    "title": "Post With Code",
    "section": "",
    "text": "1 + 1\n\n[1] 2"
  },
  {
    "objectID": "about.html",
    "href": "about.html",
    "title": "About",
    "section": "",
    "text": "About this blog"
  },
  {
    "objectID": "index.html",
    "href": "index.html",
    "title": "Fdr Blog",
    "section": "",
    "text": "Markov Chain\n\n\ncode\n\n\npython\n\n\ntidyverse\n\n\nRandom Walk\n\n\n\n\n\n\n\n\n\n\n\nOct 21, 2022\n\n\nFrancois de Ryckel\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nkmeans\n\n\ncode\n\n\nanalysis\n\n\ntidymodel\n\n\n\n\n\n\n\n\n\n\n\nOct 12, 2022\n\n\nFrancois de Ryckel\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nxgboost\n\n\ncode\n\n\nanalysis\n\n\ntidymodel\n\n\n\n\n\n\n\n\n\n\n\nOct 1, 2022\n\n\nFrancois de Ryckel\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nDecision Tree\n\n\ncode\n\n\nanalysis\n\n\n\n\n\n\n\n\n\n\n\nSep 29, 2022\n\n\nFrancois de Ryckel\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\ndecision_tree\n\n\ncode\n\n\nanalysis\n\n\n\n\n\n\n\n\n\n\n\nSep 25, 2022\n\n\nFrancois de Ryckel\n\n\n\n\n\n\n  \n\n\n\n\n\n\n\n\n\n\nnews\n\n\ncode\n\n\nanalysis\n\n\n\n\n\n\n\n\n\n\n\nSep 25, 2022\n\n\nHarlow Malloc\n\n\n\n\n\n\n  \n\n\n\n\n\n\n\n\n\n\nnews\n\n\n\n\n\n\n\n\n\n\n\nSep 22, 2022\n\n\nTristan O’Malley\n\n\n\n\n\n\nNo matching items"
  }
]